{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transfer Learning Models\n",
    "***\n",
    "### Additional modeling process using pretrained models.  \n",
    "\n",
    "\n",
    "Import neccesary packages and libraries "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os, shutil\n",
    "from keras import models\n",
    "from keras import layers\n",
    "from sklearn.metrics import confusion_matrix, f1_score\n",
    "np.random.seed(123)\n",
    "from keras.models import load_model\n",
    "from keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read in Data\n",
    "Read in data with ImageDataGenerator.  Created validation set from training dataset.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_directory = 'Alzheimer_s Dataset/test/'\n",
    "train_directory = 'Alzheimer_s Dataset/train/'\n",
    "\n",
    "data_genorator = ImageDataGenerator(rescale=1./255,validation_split=0.2)\n",
    "\n",
    "\n",
    "data_train= data_genorator.flow_from_directory( \n",
    "        train_directory, \n",
    "        subset= 'training',\n",
    "        target_size=(224, 224), \n",
    "        batch_size = 4098, \n",
    "        seed = 123)\n",
    "\n",
    "data_valid = data_genorator.flow_from_directory( \n",
    "        train_directory, \n",
    "        subset= 'validation',\n",
    "        target_size=(224, 224), \n",
    "        batch_size = 1023, \n",
    "        seed = 123)\n",
    "\n",
    "data_test= ImageDataGenerator(rescale=1./255).flow_from_directory( \n",
    "        test_directory, \n",
    "        subset= 'training',\n",
    "        target_size=(224, 224), \n",
    "        batch_size = 1279, \n",
    "        seed = 123)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Seperate lables from images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_images, train_labels = next(data_train)\n",
    "\n",
    "test_images, test_labels = next(data_test)\n",
    "\n",
    "valid_images, valid_labels = next(data_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_label(array):\n",
    "    if array[0] ==1:\n",
    "        return 0\n",
    "    elif array[1] ==1:\n",
    "        return 1\n",
    "    elif array[2] ==1:\n",
    "        return 2\n",
    "    elif array[3] ==1:\n",
    "        return 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_label_names = np.apply_along_axis(get_label,1,train_labels)\n",
    "\n",
    "test_label_names = np.apply_along_axis(get_label,1,test_labels)\n",
    "\n",
    "valid_label_names = np.apply_along_axis(get_label,1,valid_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_labels[:9]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pickle import load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_images_aug, train_labels_aug = load(open('train_aug.pickle','rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6000, 224, 224, 3)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_images_aug.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6000, 4)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_labels_aug.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = train_images.reshape(4098,150528)\n",
    "\n",
    "x_test = test_images.reshape(1279,150528)\n",
    "\n",
    "x_valid = valid_images.reshape(1023,150528)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "\n",
    "import keras\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout\n",
    "from keras.optimizers import RMSprop\n",
    "from keras.optimizers import Adam, SGD\n",
    "from keras.metrics import Recall, Precision \n",
    "from keras.callbacks import EarlyStopping"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basic Convoluted Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 12\n",
    "num_classes = 4\n",
    "epochs = 30\n",
    "\n",
    "\n",
    "y_train = keras.utils.to_categorical(train_labels, num_classes)\n",
    "\n",
    "y_valid = keras.utils.to_categorical(valid_labels, num_classes)\n",
    "\n",
    "\n",
    "cnn = models.Sequential()\n",
    "cnn.add(layers.Conv2D(64, (3, 3), activation='relu', input_shape=(224, 224,  3),use_bias=True))\n",
    "cnn.add(layers.MaxPooling2D((2, 2)))\n",
    "cnn.add(layers.Conv2D(32, (3, 3), activation='relu',use_bias=True))\n",
    "cnn.add(layers.MaxPooling2D((2, 2)))\n",
    "cnn.add(layers.Flatten())\n",
    "cnn.add(layers.Dense(32, activation='relu'))\n",
    "cnn.add(layers.Dense(4, activation='softmax'))\n",
    "\n",
    "cnn.summary()\n",
    "\n",
    "cnn.compile(loss='categorical_crossentropy',\n",
    "              optimizer= Adam(),\n",
    "              metrics=[Recall(),'accuracy'])\n",
    "\n",
    "early_stop = EarlyStopping(monitor='val_loss',patience=5,verbose=1,mode='auto')\n",
    "\n",
    "#dont forget to change\n",
    "history = cnn.fit(train_images, train_labels,\n",
    "                    batch_size=batch_size,\n",
    "                    epochs=epochs,\n",
    "                    verbose=1,\n",
    "                    callbacks = [early_stop],\n",
    "                    validation_data=(valid_images, valid_labels))\n",
    "score = cnn.evaluate(test_images, test_labels, verbose=0)\n",
    "print('test loss:', score[0])\n",
    "print('Test recall:', score[1])\n",
    "print('Test Accuracy', score[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history_df = pd.DataFrame(history.history)\n",
    "history_df.plot(figsize=(10,8))\n",
    "plt.grid(True)\n",
    "plt.gca().set_ylim(0,1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basic CNN with Augmented"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(train_images_aug.shape)\n",
    "print(train_labels_aug.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 50\n",
    "num_classes = 4\n",
    "epochs = 30\n",
    "\n",
    "cnn = models.Sequential()\n",
    "cnn.add(layers.Conv2D(64, (5, 5), activation='relu', input_shape=(224, 224,  3),use_bias=True))\n",
    "cnn.add(layers.MaxPooling2D((2, 2)))\n",
    "cnn.add(layers.Conv2D(32, (3, 3), activation='relu',use_bias=True))\n",
    "cnn.add(layers.MaxPooling2D((2, 2)))\n",
    "cnn.add(layers.Flatten())\n",
    "cnn.add(layers.Dense(32, activation='relu'))\n",
    "cnn.add(layers.Dense(4, activation='softmax'))\n",
    "\n",
    "cnn.summary()\n",
    "\n",
    "cnn.compile(loss='categorical_crossentropy',\n",
    "              optimizer= Adam(),\n",
    "              metrics=[Recall(),'accuracy'])\n",
    "\n",
    "early_stop = EarlyStopping(monitor='val_loss',patience=5,verbose=1,mode='auto')\n",
    "\n",
    "#dont forget to change\n",
    "cnn_aug_history = cnn.fit(train_images_aug, train_labels_aug,\n",
    "                    batch_size=batch_size,\n",
    "                    epochs=epochs,\n",
    "                    verbose=1,\n",
    "                    callbacks = [early_stop],\n",
    "                    validation_data=(valid_images, valid_labels))\n",
    "score = cnn.evaluate(test_images, test_labels, verbose=0)\n",
    "print('test loss:', score[0])\n",
    "print('Test recall:', score[1])\n",
    "print('Test Accuracy', score[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn_aug_history_df = pd.DataFrame(cnn_aug_history.history)\n",
    "history_df.plot(figsize=(10,8))\n",
    "plt.grid(True)\n",
    "plt.gca().set_ylim(0,1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## AlexNet Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_6\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_18 (Conv2D)           (None, 54, 54, 96)        34944     \n",
      "_________________________________________________________________\n",
      "batch_normalization_18 (Batc (None, 54, 54, 96)        384       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_7 (MaxPooling2 (None, 26, 26, 96)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_19 (Conv2D)           (None, 26, 26, 256)       614656    \n",
      "_________________________________________________________________\n",
      "batch_normalization_19 (Batc (None, 26, 26, 256)       1024      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_8 (MaxPooling2 (None, 12, 12, 256)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_20 (Conv2D)           (None, 12, 12, 384)       885120    \n",
      "_________________________________________________________________\n",
      "batch_normalization_20 (Batc (None, 12, 12, 384)       1536      \n",
      "_________________________________________________________________\n",
      "conv2d_21 (Conv2D)           (None, 12, 12, 384)       147840    \n",
      "_________________________________________________________________\n",
      "batch_normalization_21 (Batc (None, 12, 12, 384)       1536      \n",
      "_________________________________________________________________\n",
      "conv2d_22 (Conv2D)           (None, 12, 12, 256)       98560     \n",
      "_________________________________________________________________\n",
      "batch_normalization_22 (Batc (None, 12, 12, 256)       1024      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_9 (MaxPooling2 (None, 5, 5, 256)         0         \n",
      "_________________________________________________________________\n",
      "flatten_5 (Flatten)          (None, 6400)              0         \n",
      "_________________________________________________________________\n",
      "dense_15 (Dense)             (None, 4096)              26218496  \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 4096)              0         \n",
      "_________________________________________________________________\n",
      "dense_16 (Dense)             (None, 4096)              16781312  \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 4096)              0         \n",
      "_________________________________________________________________\n",
      "dense_17 (Dense)             (None, 4)                 16388     \n",
      "=================================================================\n",
      "Total params: 44,802,820\n",
      "Trainable params: 44,800,068\n",
      "Non-trainable params: 2,752\n",
      "_________________________________________________________________\n",
      "Epoch 1/30\n",
      "171/171 [==============================] - 215s 1s/step - loss: 2.8217 - recall_5: 0.3843 - accuracy: 0.4822 - val_loss: 6.7850 - val_recall_5: 0.5015 - val_accuracy: 0.5024\n",
      "Epoch 2/30\n",
      "171/171 [==============================] - 184s 1s/step - loss: 1.0437 - recall_5: 0.3953 - accuracy: 0.5237 - val_loss: 1.2500 - val_recall_5: 0.5044 - val_accuracy: 0.5054\n",
      "Epoch 3/30\n",
      "171/171 [==============================] - 169s 989ms/step - loss: 0.9792 - recall_5: 0.4202 - accuracy: 0.5547 - val_loss: 1.4756 - val_recall_5: 0.2874 - val_accuracy: 0.4888\n",
      "Epoch 4/30\n",
      "171/171 [==============================] - 167s 977ms/step - loss: 0.8978 - recall_5: 0.4746 - accuracy: 0.6003 - val_loss: 1.3276 - val_recall_5: 0.0978 - val_accuracy: 0.3060\n",
      "Epoch 5/30\n",
      " 22/171 [==>...........................] - ETA: 2:08 - loss: 0.8564 - recall_5: 0.5189 - accuracy: 0.6402"
     ]
    }
   ],
   "source": [
    "batch_size = 24\n",
    "num_classes = 4\n",
    "epochs = 30\n",
    "\n",
    "alex = keras.models.Sequential([\n",
    "    keras.layers.Conv2D(filters=96, kernel_size=(11,11), strides=(4,4), activation='relu', input_shape=(224,224,3)),\n",
    "    keras.layers.BatchNormalization(),\n",
    "    keras.layers.MaxPool2D(pool_size=(3,3), strides=(2,2)),\n",
    "    keras.layers.Conv2D(filters=256, kernel_size=(5,5), strides=(1,1), activation='relu', padding=\"same\"),\n",
    "    keras.layers.BatchNormalization(),\n",
    "    keras.layers.MaxPool2D(pool_size=(3,3), strides=(2,2)),\n",
    "    keras.layers.Conv2D(filters=384, kernel_size=(3,3), strides=(1,1), activation='relu', padding=\"same\"),\n",
    "    keras.layers.BatchNormalization(),\n",
    "    keras.layers.Conv2D(filters=384, kernel_size=(1,1), strides=(1,1), activation='relu', padding=\"same\"),\n",
    "    keras.layers.BatchNormalization(),\n",
    "    keras.layers.Conv2D(filters=256, kernel_size=(1,1), strides=(1,1), activation='relu', padding=\"same\"),\n",
    "    keras.layers.BatchNormalization(),\n",
    "    keras.layers.MaxPool2D(pool_size=(3,3), strides=(2,2)),\n",
    "    keras.layers.Flatten(),\n",
    "    keras.layers.Dense(4096, activation='relu'),\n",
    "    keras.layers.Dropout(0.5),\n",
    "    keras.layers.Dense(4096, activation='relu'),\n",
    "    keras.layers.Dropout(0.5),\n",
    "    keras.layers.Dense(4, activation='softmax')\n",
    "])\n",
    "\n",
    "alex.summary()\n",
    "\n",
    "alex.compile(loss='categorical_crossentropy',\n",
    "              optimizer= Adam(),\n",
    "              metrics=[Recall(),'accuracy'])\n",
    "\n",
    "early_stop = EarlyStopping(monitor='val_loss',patience=5,verbose=1,mode='auto')\n",
    "\n",
    "alex_history = alex.fit(train_images, train_labels,\n",
    "                    batch_size=batch_size,\n",
    "                    epochs=epochs,\n",
    "                    verbose=1,\n",
    "                    callbacks = [early_stop],\n",
    "                    validation_data=(valid_images, valid_labels))\n",
    "\n",
    "score = alex.evaluate(test_images, test_labels, verbose=0)\n",
    "\n",
    "print('test loss:', score[0])\n",
    "print('Test recall:', score[1])\n",
    "print('Test Accuracy', score[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 54, 54, 96)        34944     \n",
      "_________________________________________________________________\n",
      "batch_normalization (BatchNo (None, 54, 54, 96)        384       \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 26, 26, 96)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 26, 26, 256)       614656    \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 26, 26, 256)       1024      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 12, 12, 256)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 12, 12, 384)       885120    \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 12, 12, 384)       1536      \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 12, 12, 384)       147840    \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 12, 12, 384)       1536      \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 12, 12, 256)       98560     \n",
      "_________________________________________________________________\n",
      "batch_normalization_4 (Batch (None, 12, 12, 256)       1024      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 5, 5, 256)         0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 6400)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 4096)              26218496  \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 4096)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 4096)              16781312  \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 4096)              0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 4)                 16388     \n",
      "=================================================================\n",
      "Total params: 44,802,820\n",
      "Trainable params: 44,800,068\n",
      "Non-trainable params: 2,752\n",
      "_________________________________________________________________\n",
      "Epoch 1/30\n",
      "250/250 [==============================] - 342s 1s/step - loss: 2.1965 - recall: 0.3340 - accuracy: 0.4697 - val_loss: 1.5072 - val_recall: 0.0577 - val_accuracy: 0.1466\n",
      "Epoch 2/30\n",
      "250/250 [==============================] - 252s 1s/step - loss: 1.0688 - recall: 0.4020 - accuracy: 0.5443 - val_loss: 1.8287 - val_recall: 0.1036 - val_accuracy: 0.1750\n",
      "Epoch 3/30\n",
      "250/250 [==============================] - 216s 863ms/step - loss: 1.0737 - recall: 0.3952 - accuracy: 0.5407 - val_loss: 2.0272 - val_recall: 0.1085 - val_accuracy: 0.2102\n",
      "Epoch 4/30\n",
      "250/250 [==============================] - 239s 957ms/step - loss: 0.9271 - recall: 0.4552 - accuracy: 0.5843 - val_loss: 5.3877 - val_recall: 0.5015 - val_accuracy: 0.5034\n",
      "Epoch 5/30\n",
      "250/250 [==============================] - 198s 792ms/step - loss: 0.9360 - recall: 0.4485 - accuracy: 0.5898 - val_loss: 1.2616 - val_recall: 0.0596 - val_accuracy: 0.3304\n",
      "Epoch 6/30\n",
      "250/250 [==============================] - 195s 781ms/step - loss: 0.8886 - recall: 0.4797 - accuracy: 0.6130 - val_loss: 1.6535 - val_recall: 0.2248 - val_accuracy: 0.3382\n",
      "Epoch 7/30\n",
      "250/250 [==============================] - 214s 855ms/step - loss: 0.7818 - recall: 0.5270 - accuracy: 0.6473 - val_loss: 1.9173 - val_recall: 0.1212 - val_accuracy: 0.1535\n",
      "Epoch 8/30\n",
      "250/250 [==============================] - 197s 790ms/step - loss: 0.6798 - recall: 0.6000 - accuracy: 0.6933 - val_loss: 1.2615 - val_recall: 0.0762 - val_accuracy: 0.2141\n",
      "Epoch 9/30\n",
      "250/250 [==============================] - 194s 777ms/step - loss: 0.7386 - recall: 0.5978 - accuracy: 0.6927 - val_loss: 2.8833 - val_recall: 0.1496 - val_accuracy: 0.1584\n",
      "Epoch 10/30\n",
      "250/250 [==============================] - 194s 778ms/step - loss: 0.5903 - recall: 0.6720 - accuracy: 0.7393 - val_loss: 0.9864 - val_recall: 0.4536 - val_accuracy: 0.5044\n",
      "Epoch 11/30\n",
      "250/250 [==============================] - 198s 792ms/step - loss: 0.5307 - recall: 0.7312 - accuracy: 0.7785 - val_loss: 1.3162 - val_recall: 0.3695 - val_accuracy: 0.4379\n",
      "Epoch 12/30\n",
      "250/250 [==============================] - 193s 773ms/step - loss: 0.5692 - recall: 0.7245 - accuracy: 0.7703 - val_loss: 4.9806 - val_recall: 0.1427 - val_accuracy: 0.1466\n",
      "Epoch 13/30\n",
      "250/250 [==============================] - 194s 777ms/step - loss: 0.5519 - recall: 0.7143 - accuracy: 0.7643 - val_loss: 1.5780 - val_recall: 0.3558 - val_accuracy: 0.3998\n",
      "Epoch 14/30\n",
      "250/250 [==============================] - 194s 777ms/step - loss: 0.4332 - recall: 0.7887 - accuracy: 0.8203 - val_loss: 1.3404 - val_recall: 0.4360 - val_accuracy: 0.4897\n",
      "Epoch 15/30\n",
      "250/250 [==============================] - 209s 835ms/step - loss: 0.3699 - recall: 0.8270 - accuracy: 0.8472 - val_loss: 1.1399 - val_recall: 0.4516 - val_accuracy: 0.4936\n",
      "Epoch 00015: early stopping\n",
      "test loss: 0.8060972690582275\n",
      "Test recall: 0.5215011835098267\n",
      "Test Accuracy 0.6231430768966675\n"
     ]
    }
   ],
   "source": [
    "batch_size = 24\n",
    "num_classes = 4\n",
    "epochs = 30\n",
    "\n",
    "alex = keras.models.Sequential([\n",
    "    keras.layers.Conv2D(filters=96, kernel_size=(11,11), strides=(4,4), activation='relu', input_shape=(224,224,3)),\n",
    "    keras.layers.BatchNormalization(),\n",
    "    keras.layers.MaxPool2D(pool_size=(3,3), strides=(2,2)),\n",
    "    keras.layers.Conv2D(filters=256, kernel_size=(5,5), strides=(1,1), activation='relu', padding=\"same\"),\n",
    "    keras.layers.BatchNormalization(),\n",
    "    keras.layers.MaxPool2D(pool_size=(3,3), strides=(2,2)),\n",
    "    keras.layers.Conv2D(filters=384, kernel_size=(3,3), strides=(1,1), activation='relu', padding=\"same\"),\n",
    "    keras.layers.BatchNormalization(),\n",
    "    keras.layers.Conv2D(filters=384, kernel_size=(1,1), strides=(1,1), activation='relu', padding=\"same\"),\n",
    "    keras.layers.BatchNormalization(),\n",
    "    keras.layers.Conv2D(filters=256, kernel_size=(1,1), strides=(1,1), activation='relu', padding=\"same\"),\n",
    "    keras.layers.BatchNormalization(),\n",
    "    keras.layers.MaxPool2D(pool_size=(3,3), strides=(2,2)),\n",
    "    keras.layers.Flatten(),\n",
    "    keras.layers.Dense(4096, activation='relu'),\n",
    "    keras.layers.Dropout(0.5),\n",
    "    keras.layers.Dense(4096, activation='relu'),\n",
    "    keras.layers.Dropout(0.5),\n",
    "    keras.layers.Dense(4, activation='softmax')\n",
    "])\n",
    "\n",
    "alex.summary()\n",
    "\n",
    "alex.compile(loss='categorical_crossentropy',\n",
    "              optimizer= Adam(),\n",
    "              metrics=[Recall(),'accuracy'])\n",
    "\n",
    "early_stop = EarlyStopping(monitor='val_loss',patience=5,verbose=1,mode='auto')\n",
    "\n",
    "alex_history = alex.fit(train_images_aug, train_labels_aug,\n",
    "                    batch_size=batch_size,\n",
    "                    epochs=epochs,\n",
    "                    verbose=1,\n",
    "                    callbacks = [early_stop],\n",
    "                    validation_data=(valid_images, valid_labels))\n",
    "\n",
    "score = alex.evaluate(test_images, test_labels, verbose=0)\n",
    "\n",
    "print('test loss:', score[0])\n",
    "print('Test recall:', score[1])\n",
    "print('Test Accuracy', score[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history_df = pd.DataFrame(alex_history.history)\n",
    "history_df.plot(figsize=(10,8))\n",
    "plt.grid(True)\n",
    "plt.gca().set_ylim(0,1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_5\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_15 (Conv2D)           (None, 224, 224, 32)      98336     \n",
      "_________________________________________________________________\n",
      "batch_normalization_15 (Batc (None, 224, 224, 32)      128       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_6 (MaxPooling2 (None, 105, 105, 32)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_16 (Conv2D)           (None, 105, 105, 32)      262176    \n",
      "_________________________________________________________________\n",
      "batch_normalization_16 (Batc (None, 105, 105, 32)      128       \n",
      "_________________________________________________________________\n",
      "average_pooling2d_6 (Average (None, 49, 49, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_17 (Conv2D)           (None, 49, 49, 64)        131136    \n",
      "_________________________________________________________________\n",
      "batch_normalization_17 (Batc (None, 49, 49, 64)        256       \n",
      "_________________________________________________________________\n",
      "average_pooling2d_7 (Average (None, 6, 6, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten_4 (Flatten)          (None, 2304)              0         \n",
      "_________________________________________________________________\n",
      "dense_12 (Dense)             (None, 1024)              2360320   \n",
      "_________________________________________________________________\n",
      "dense_13 (Dense)             (None, 1024)              1049600   \n",
      "_________________________________________________________________\n",
      "dense_14 (Dense)             (None, 4)                 4100      \n",
      "=================================================================\n",
      "Total params: 3,906,180\n",
      "Trainable params: 3,905,924\n",
      "Non-trainable params: 256\n",
      "_________________________________________________________________\n",
      "Epoch 1/30\n",
      "120/120 [==============================] - 4553s 38s/step - loss: 1.1638 - recall_4: 0.3640 - accuracy: 0.5283 - val_loss: 14.3061 - val_recall_4: 0.0108 - val_accuracy: 0.0108\n",
      "Epoch 2/30\n",
      "120/120 [==============================] - 3972s 33s/step - loss: 0.8628 - recall_4: 0.4735 - accuracy: 0.6137 - val_loss: 3.6027 - val_recall_4: 0.0137 - val_accuracy: 0.0186\n",
      "Epoch 3/30\n",
      "120/120 [==============================] - 3711s 31s/step - loss: 0.7599 - recall_4: 0.5555 - accuracy: 0.6660 - val_loss: 3.5895 - val_recall_4: 0.1261 - val_accuracy: 0.1388\n",
      "Epoch 4/30\n",
      "120/120 [==============================] - 3656s 30s/step - loss: 0.6486 - recall_4: 0.6472 - accuracy: 0.7170 - val_loss: 1.9111 - val_recall_4: 0.4682 - val_accuracy: 0.4848\n",
      "Epoch 5/30\n",
      "120/120 [==============================] - 4113s 34s/step - loss: 0.5184 - recall_4: 0.7255 - accuracy: 0.7758 - val_loss: 1.2973 - val_recall_4: 0.4907 - val_accuracy: 0.5024\n",
      "Epoch 6/30\n",
      "120/120 [==============================] - 3885s 32s/step - loss: 0.4239 - recall_4: 0.7952 - accuracy: 0.8183 - val_loss: 1.4866 - val_recall_4: 0.5640 - val_accuracy: 0.5846\n",
      "Epoch 7/30\n",
      "120/120 [==============================] - 3996s 33s/step - loss: 0.3443 - recall_4: 0.8430 - accuracy: 0.8585 - val_loss: 2.2961 - val_recall_4: 0.4858 - val_accuracy: 0.4917\n",
      "Epoch 8/30\n",
      "120/120 [==============================] - 3689s 31s/step - loss: 0.2318 - recall_4: 0.9008 - accuracy: 0.9097 - val_loss: 0.7758 - val_recall_4: 0.6940 - val_accuracy: 0.6970\n",
      "Epoch 9/30\n",
      "120/120 [==============================] - 3584s 30s/step - loss: 0.1765 - recall_4: 0.9287 - accuracy: 0.9320 - val_loss: 1.9738 - val_recall_4: 0.6706 - val_accuracy: 0.6745\n",
      "Epoch 10/30\n",
      "120/120 [==============================] - 3576s 30s/step - loss: 0.1280 - recall_4: 0.9520 - accuracy: 0.9538 - val_loss: 0.5783 - val_recall_4: 0.7889 - val_accuracy: 0.7937\n",
      "Epoch 11/30\n",
      "120/120 [==============================] - 3579s 30s/step - loss: 0.0929 - recall_4: 0.9663 - accuracy: 0.9677 - val_loss: 0.8041 - val_recall_4: 0.7605 - val_accuracy: 0.7683\n",
      "Epoch 12/30\n",
      "120/120 [==============================] - 3585s 30s/step - loss: 0.1235 - recall_4: 0.9547 - accuracy: 0.9560 - val_loss: 0.7211 - val_recall_4: 0.7351 - val_accuracy: 0.7410\n",
      "Epoch 13/30\n",
      "120/120 [==============================] - 3583s 30s/step - loss: 0.0689 - recall_4: 0.9752 - accuracy: 0.9758 - val_loss: 0.4067 - val_recall_4: 0.8543 - val_accuracy: 0.8592\n",
      "Epoch 14/30\n",
      "120/120 [==============================] - 3581s 30s/step - loss: 0.0689 - recall_4: 0.9742 - accuracy: 0.9747 - val_loss: 1.6755 - val_recall_4: 0.7019 - val_accuracy: 0.7028\n",
      "Epoch 15/30\n",
      "120/120 [==============================] - 3734s 31s/step - loss: 0.0309 - recall_4: 0.9897 - accuracy: 0.9902 - val_loss: 0.3527 - val_recall_4: 0.8807 - val_accuracy: 0.8837\n",
      "Epoch 16/30\n",
      "120/120 [==============================] - 4925s 41s/step - loss: 0.0686 - recall_4: 0.9772 - accuracy: 0.9775 - val_loss: 2.5838 - val_recall_4: 0.6002 - val_accuracy: 0.6051\n",
      "Epoch 17/30\n",
      "120/120 [==============================] - 4718s 39s/step - loss: 0.0568 - recall_4: 0.9785 - accuracy: 0.9795 - val_loss: 0.4235 - val_recall_4: 0.8671 - val_accuracy: 0.8671\n",
      "Epoch 18/30\n",
      "120/120 [==============================] - 4165s 35s/step - loss: 0.0110 - recall_4: 0.9973 - accuracy: 0.9975 - val_loss: 0.5834 - val_recall_4: 0.8348 - val_accuracy: 0.8368\n",
      "Epoch 19/30\n",
      "120/120 [==============================] - 4026s 34s/step - loss: 0.0295 - recall_4: 0.9893 - accuracy: 0.9895 - val_loss: 0.7140 - val_recall_4: 0.8299 - val_accuracy: 0.8299\n",
      "Epoch 20/30\n",
      "120/120 [==============================] - 4263s 36s/step - loss: 0.0886 - recall_4: 0.9670 - accuracy: 0.9673 - val_loss: 1.0879 - val_recall_4: 0.7429 - val_accuracy: 0.7458\n",
      "Epoch 00020: early stopping\n",
      "test loss: 2.3721485137939453\n",
      "Test recall: 0.6606724262237549\n",
      "Test Accuracy 0.6637998223304749\n"
     ]
    }
   ],
   "source": [
    "batch_size = 50\n",
    "num_classes = 4\n",
    "epochs = 30\n",
    "np.random.seed(7)\n",
    "\n",
    "frontiers = models.Sequential()\n",
    "\n",
    "frontiers.add(layers.Conv2D(32,(32,32),padding= 'same',activation = 'relu', input_shape=(224,224,3),use_bias=True))\n",
    "frontiers.add(layers.BatchNormalization())\n",
    "frontiers.add(layers.MaxPooling2D((16,16),strides=2))\n",
    "frontiers.add(layers.Conv2D(32,(16,16),padding ='same',activation = 'relu',use_bias=True))\n",
    "frontiers.add(layers.BatchNormalization())\n",
    "frontiers.add(layers.AveragePooling2D((8,8),strides=2))\n",
    "frontiers.add(layers.Conv2D(64,(8,8),padding = 'same',activation = 'relu',use_bias=True))\n",
    "frontiers.add(layers.BatchNormalization())\n",
    "frontiers.add(layers.AveragePooling2D((8,8)))\n",
    "frontiers.add(layers.Flatten())\n",
    "frontiers.add(Dense(1024,activation ='relu'))\n",
    "frontiers.add(Dense(1024,activation ='relu'))\n",
    "frontiers.add(Dense(4,activation = 'softmax'))\n",
    "\n",
    "frontiers.summary()\n",
    "\n",
    "frontiers.compile(loss='categorical_crossentropy',\n",
    "              optimizer= Adam(),\n",
    "              metrics=[Recall(),'accuracy'])\n",
    "\n",
    "early_stop = EarlyStopping(monitor='val_loss',patience=5,verbose=1,mode='auto')\n",
    "\n",
    "frontiers_history = frontiers.fit(train_images_aug, train_labels_aug,\n",
    "                    batch_size=batch_size,\n",
    "                    epochs=epochs,\n",
    "                    verbose=1,\n",
    "                    callbacks = [early_stop],\n",
    "                    validation_data=(valid_images, valid_labels))\n",
    "\n",
    "score = frontiers.evaluate(test_images, test_labels, verbose=0)\n",
    "\n",
    "print('test loss:', score[0])\n",
    "print('Test recall:', score[1])\n",
    "print('Test Accuracy', score[2])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.applications.resnet50 import ResNet50\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras.applications.resnet50 import preprocess_input, decode_predictions\n",
    "from keras.applications.resnet50 import decode_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/resnet/resnet50_weights_tf_dim_ordering_tf_kernels.h5\n",
      "102973440/102967424 [==============================] - 22s 0us/step\n"
     ]
    }
   ],
   "source": [
    "model_res = keras.applications.resnet50.ResNet50(weights='imagenet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'tensorflow.python.framework.ops.EagerTensor' object has no attribute 'reshape'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-42-cc4dc85e1574>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mimages_resized\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m6000\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m224\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m672\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: 'tensorflow.python.framework.ops.EagerTensor' object has no attribute 'reshape'"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "images_resized = tf.image.resize(train_images_aug, [224,224])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = keras.applications.resnet50.preprocess_input(images_resized*255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_proba = model_res.predict(inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "`decode_predictions` expects a batch of predictions (i.e. a 2D array of shape (samples, 1000)). Found array with shape: ()",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-41-a08c3a82607b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtop_K\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapplications\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresnet50\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode_predictions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mY_proba\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtop\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/keras/applications/resnet.py\u001b[0m in \u001b[0;36mdecode_predictions\u001b[0;34m(preds, top)\u001b[0m\n\u001b[1;32m    541\u001b[0m     \u001b[0mValueError\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mIn\u001b[0m \u001b[0mcase\u001b[0m \u001b[0mof\u001b[0m \u001b[0minvalid\u001b[0m \u001b[0mshape\u001b[0m \u001b[0mof\u001b[0m \u001b[0mthe\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mpreds\u001b[0m\u001b[0;31m`\u001b[0m \u001b[0marray\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mmust\u001b[0m \u001b[0mbe\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0mD\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    542\u001b[0m   \"\"\"\n\u001b[0;32m--> 543\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mimagenet_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode_predictions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpreds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtop\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtop\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    544\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    545\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/keras/applications/imagenet_utils.py\u001b[0m in \u001b[0;36mdecode_predictions\u001b[0;34m(preds, top)\u001b[0m\n\u001b[1;32m    135\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    136\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpreds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m2\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mpreds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m1000\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 137\u001b[0;31m     raise ValueError('`decode_predictions` expects '\n\u001b[0m\u001b[1;32m    138\u001b[0m                      \u001b[0;34m'a batch of predictions '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    139\u001b[0m                      \u001b[0;34m'(i.e. a 2D array of shape (samples, 1000)). '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: `decode_predictions` expects a batch of predictions (i.e. a 2D array of shape (samples, 1000)). Found array with shape: ()"
     ]
    }
   ],
   "source": [
    "top_K = keras.applications.resnet50.decode_predictions(Y_proba, top=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:5: SyntaxWarning: 'str' object is not callable; perhaps you missed a comma?\n",
      "<>:5: SyntaxWarning: 'str' object is not callable; perhaps you missed a comma?\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "`decode_predictions` expects a batch of predictions (i.e. a 2D array of shape (samples, 1000)). Found array with shape: ()",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-37-27d467df324b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtop_K\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapplications\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresnet50\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode_predictions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mY_proba\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtop\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mimage_index\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_images_aug\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Image #{}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mclass_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_proba\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtop_K\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mimage_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m' {} - {:12s}{:.2f}%.format'\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclass_id\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mY_proba\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/keras/applications/resnet.py\u001b[0m in \u001b[0;36mdecode_predictions\u001b[0;34m(preds, top)\u001b[0m\n\u001b[1;32m    541\u001b[0m     \u001b[0mValueError\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mIn\u001b[0m \u001b[0mcase\u001b[0m \u001b[0mof\u001b[0m \u001b[0minvalid\u001b[0m \u001b[0mshape\u001b[0m \u001b[0mof\u001b[0m \u001b[0mthe\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mpreds\u001b[0m\u001b[0;31m`\u001b[0m \u001b[0marray\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mmust\u001b[0m \u001b[0mbe\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0mD\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    542\u001b[0m   \"\"\"\n\u001b[0;32m--> 543\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mimagenet_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode_predictions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpreds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtop\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtop\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    544\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    545\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/keras/applications/imagenet_utils.py\u001b[0m in \u001b[0;36mdecode_predictions\u001b[0;34m(preds, top)\u001b[0m\n\u001b[1;32m    135\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    136\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpreds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m2\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mpreds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m1000\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 137\u001b[0;31m     raise ValueError('`decode_predictions` expects '\n\u001b[0m\u001b[1;32m    138\u001b[0m                      \u001b[0;34m'a batch of predictions '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    139\u001b[0m                      \u001b[0;34m'(i.e. a 2D array of shape (samples, 1000)). '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: `decode_predictions` expects a batch of predictions (i.e. a 2D array of shape (samples, 1000)). Found array with shape: ()"
     ]
    }
   ],
   "source": [
    "\n",
    "for image_index in range(len(train_images_aug)):\n",
    "    print('Image #{}'.format(image_index))\n",
    "    for class_id, name, Y_proba in top_K[image_index]:\n",
    "        print(' {} - {:12s}{:.2f}%.format'(class_id,name,Y_proba*100))\n",
    "    print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
